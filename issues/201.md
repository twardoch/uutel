Read @external/ext/repo-tldr.txt

```
 $ uutel test
ğŸ§ª Testing engine: my-custom-llm/codex-large
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ”§ Verbose mode enabled
ğŸ¯ Using engine: my-custom-llm/codex-large
âš™ï¸  Parameters: max_tokens=50, temperature=0.7
â³ Generating completion...
16:08:41 - LiteLLM:WARNING: utils.py:539 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.
SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
Final returned optional params: {'temperature': 0.7, 'max_tokens': 50}
This is a mock response from Codex provider for model codex-large. Received 1 messages. In a real implementation, this would call the actual Codex API.
âœ… Completion successful (151 characters)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… Test completed successfully!
ğŸ’¡ Engine 'my-custom-llm/codex-large' is working correctly
This is a mock response from Codex provider for model codex-large. Received 1 messages. In a real implementation, this would call the actual Codex API.
```

I REALLY FINALLY WANT ACTUAL REAL IMPLEMENTATIONS, not "mock"!!! 

You need to port them from:

- @external/ext/ai-sdk-provider-claude-code.txt
- @external/ext/ai-sdk-provider-gemini-cli.txt
- @external/ext/cloud-code-ai-provider.txt
- @external/ext/codex-ai-provider.txt
