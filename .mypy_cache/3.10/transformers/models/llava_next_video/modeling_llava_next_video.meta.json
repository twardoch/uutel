{"data_mtime":1759164821,"dep_lines":[44,35,42,43,28,30,31,32,33,34,35,22,23,24,26,27,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],"dep_prios":[5,10,5,5,10,5,5,5,5,5,5,10,5,5,10,10,5,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30],"dependencies":["transformers.models.llava_next_video.configuration_llava_next_video","transformers.utils.logging","transformers.utils.deprecation","transformers.models.auto","torch.nn","transformers.activations","transformers.generation","transformers.image_processing_utils","transformers.modeling_outputs","transformers.modeling_utils","transformers.utils","math","dataclasses","typing","numpy","torch","builtins","networkx.algorithms.approximation","pyexpat.model","networkx.algorithms.coloring","networkx.algorithms.operators","altair.vegalite.v5.api","networkx.algorithms.community","pyexpat.errors","networkx.algorithms.chordal","networkx.algorithms.connectivity","networkx.algorithms.shortest_paths","paddle._typing.libs.libpaddle.eager.ops.legacy","networkx.algorithms.components","multiprocessing.reduction","networkx.algorithms.isomorphism","paddle._typing.libs.libpaddle.eager","paddle._typing.libs.libpaddle.op_proto_and_checker_maker","paddle._typing.libs.libpaddle.pir","networkx.algorithms.centrality","networkx.algorithms.lowest_common_ancestors","altair.vegalite.v5.schema.mixins","networkx.drawing.nx_pydot","networkx.linalg.modularitymatrix","networkx.classes.filters","networkx.algorithms.tree","paddle._typing.libs.libpaddle.var_names","networkx.algorithms.clique","pydantic.v1.dataclasses","networkx.linalg.bethehessianmatrix","networkx.classes.coreviews","networkx.algorithms.cluster","altair.vegalite.v5.schema.core","altair.vegalite.v5.schema","networkx.classes.graphviews","networkx.linalg.graphmatrix","networkx.linalg.spectrum","networkx.algorithms.assortativity","networkx.algorithms.node_classification","time","networkx.algorithms.bipartite","pydantic.dataclasses","altair.vegalite.v5.schema.channels","networkx.algorithms.tournament","networkx.algorithms.traversal","networkx.linalg.attrmatrix","networkx.drawing.nx_agraph","networkx.linalg.laplacianmatrix","networkx.algorithms.link_analysis","networkx.classes.reportviews","networkx.algorithms.flow","altair.vegalite.v5.compiler","_frozen_importlib","_typeshed","abc","collections","logging","torch._C","torch._C._VariableFunctions","torch._tensor","torch.nn.modules","torch.nn.modules.conv","torch.nn.modules.linear","torch.nn.modules.loss","torch.nn.modules.module","torch.nn.modules.pooling","torch.nn.parameter","transformers.configuration_utils","transformers.generation.utils","transformers.integrations","transformers.integrations.peft","transformers.models.auto.auto_factory","transformers.models.auto.modeling_auto","transformers.utils.doc","transformers.utils.generic","transformers.utils.hub","transformers.utils.import_utils","types","typing_extensions"],"hash":"9db2d2d71af5260bceb5509b87cf416fe31c589b","id":"transformers.models.llava_next_video.modeling_llava_next_video","ignore_all":true,"interface_hash":"fab6641c0a56a348ab80bfac7cb6e03564cb4261","mtime":1758626585,"options":{"allow_redefinition":false,"allow_untyped_globals":false,"always_false":[],"always_true":[],"bazel":false,"check_untyped_defs":true,"disable_bytearray_promotion":false,"disable_error_code":[],"disable_memoryview_promotion":false,"disabled_error_codes":[],"disallow_any_decorated":false,"disallow_any_explicit":false,"disallow_any_expr":false,"disallow_any_generics":true,"disallow_any_unimported":false,"disallow_incomplete_defs":true,"disallow_subclassing_any":true,"disallow_untyped_calls":false,"disallow_untyped_decorators":true,"disallow_untyped_defs":true,"enable_error_code":[],"enabled_error_codes":[],"extra_checks":false,"follow_imports":"normal","follow_imports_for_stubs":false,"follow_untyped_imports":false,"ignore_errors":false,"ignore_missing_imports":true,"implicit_optional":false,"implicit_reexport":false,"local_partial_types":false,"mypyc":false,"old_type_inference":false,"platform":"darwin","plugins":[],"strict_bytes":false,"strict_concatenate":false,"strict_equality":true,"strict_optional":true,"warn_no_return":true,"warn_return_any":true,"warn_unreachable":true,"warn_unused_ignores":true},"path":"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/models/llava_next_video/modeling_llava_next_video.py","plugin_data":null,"size":45706,"suppressed":[],"version_id":"1.15.0"}